## Gradient Descent Review

1. Gradient descent is a technique that finds the minimum solution of a function.
   In this case, we can assume the solution is minimum when the gradient of the 
   solution is 0 or close to 0.
   
   Write a function that would solve `f(x) = x^2 + 2x`. 
   
   In machine learning, this function is often a loss/error function and you are
   trying to find the solution that would minimize error.

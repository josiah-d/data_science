For this warmup we will revisit our ReadyChef dataset and try to build some interesting features from our user transaction data.

You cannot simply throw all of your data as is into a machine learning algorithm. Feature engineering is a 
critical component of the machine learning pipeline. At a bare minimum, you will need to quantify all your
features (machine learning algorithms require numerical representations of data), and if you want good performance,
 you will have to think about what features or combinations of features might help explain the data better.

### SQL

Overall, the company would like to maximize revenue and it'd be nice to understand which users tend to buy things
 on the site. If they aren't buying anything (or if we could predict non-buying), maybe the company could do something about it.

1. First start the postgres server. Create a database named `readychef` by logging into `psql` and type 
   `CREATE DATABASE readychef;`. Log out of `psql` with `\q`.

1. Load in the `readychef.sql` database dump to Postgres (`psql -f data/readychef.sql readychef`). It will throw 
   a few warnings about role. Do not worry about those.

   Here is what the tables should look like.

    ```
    $ psql readychef

    readychef=# \dt
            List of relations
    Schema |   Name    | Type  |    Owner
    --------+-----------+-------+-------------
    public | events    | table | jeffreytang
    public | meals     | table | jeffreytang
    public | referrals | table | jeffreytang
    public | users     | table | jeffreytang
    public | visits    | table | jeffreytang
   (5 rows)

   readychef=# \d events
             Table "public.events"
    Column  |       Type        | Modifiers
   ---------+-------------------+-----------
    dt      | date              |
    userid  | integer           |
    meal_id | integer           |
    event   | character varying |
    ```

1. Create a [materialized view](http://www.postgresql.org/docs/9.3/static/rules-materializedviews.html) that stores the following for each user:
    * Total meals bought
    * Total dollars spent
    * Average meals bought per month
    * Average dollar spend per month
    * Average # of visits per month


## Extras: Ranking

Let's start with finding out the attributes of our most frequent purchasers. These users are likely our most profitable users, though we'll compute user lifetime value a little later.  
Postgres [window functions](http://www.postgresql.org/docs/9.1/static/tutorial-window.html) will help us here.

1. Create 5 groups of users, ranked by how many purchases the user made (i.e. group 1 will be the users who bought the most, group 5 the users who bought the least).

2. How many purchases did each group have on average?

## Extras: Event actions by campaign/referral

Different events were generated by different campaigns. Let's see if there's anything to be gained by looking at each campaign separately.

1. Group the data by referral (e.g. Facebook, Twitter, etc.) and compute the number of events for each event type for each campaign (i.e. did more users buy through Facebook or Twitter?). 

1. Those give us absolute numbers but let's see what it looks like through proportions (i.e. What percentage of users purchased from Facebook? From Twitter?).

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning assignment\n",
    "\n",
    "Hi folks. Today we're going to be training a convnet to recognize desserts using transfer learning, then comparing it to a simple convnet. This exercise is quite memory and CPU intensive so try to close any unnecessary programs before you begin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Be sure to run this docker container from the command line with:\n",
    ">\n",
    "> ```sh\n",
    "> docker run -it --name tensorflowboard -p 8889:8888 -p 6006:6006 -v \"$PWD\":/tf tensorflow/tensorflow:2.0.0a0-py3-jupyter\n",
    "> ```\n",
    "> to run and use tensorflowboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Data\n",
    "Inspect the data/ folder. To make it easy to load images into Keras, it's been split into a training and validation folders, with an additional holdout set to evaluate model performance at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mholdout_more\u001b[0m/   \u001b[01;34mtrain_more\u001b[0m/   \u001b[01;34mvalidation_more\u001b[0m/\r\n",
      "\u001b[01;34mholdout_small\u001b[0m/  \u001b[01;34mtrain_small\u001b[0m/  \u001b[01;34mvalidation_small\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Simple ConvNet\n",
    "1. Using the create_model function in simple_cnn.py (this is the same ConvNet you built yesterday), create a keras model. Use 100x100x3 (100 pixels square with channels for RGB) as the input size while testing to save time, but we will increase this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simple_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_cnn.create_model((100,100,3), n_categories=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Previously, we used model.fit() to run the model. However, the fit() method will load all of your data into memory, which is generally unusable for large datasets. To deal with this, we'll be using data generators, which load data on the fly. The keras ImageDataGenerator also makes it very easy to implement data augmentation, which we can use to increase our validation accuracy.  \n",
    "Make two image data generators: one for training data and one for validation. for both, use the Xception preprocessor, which performs a couple quick scaling and transformation operations.  \n",
    "\n",
    "```python\n",
    "from keras.applications.xception import preprocess_input\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "You can decide what image augmentation to use in the training datagen, but don't use augmentation in the validation datagen as we want that to be indicative of real world inputs to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainimggen = ImageDataGenerator(preprocessing_function=preprocess_input, \n",
    "                                  horizontal_flip=True, \n",
    "                                  rotation_range=30, \n",
    "                                  width_shift_range=3, \n",
    "                                  height_shift_range=3,\n",
    "                                  brightness_range=None,\n",
    "                                  shear_range=3,\n",
    "                                  zoom_range=3,\n",
    "                                  channel_shift_range=3)\n",
    "validationimggen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using your image datagens, use flow_from_directory to make two generators, one for training and one for validation.  Start with target_size 100x100 and batch_size 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcarrot_cake\u001b[0m/   \u001b[01;34mpanna_cotta\u001b[0m/      \u001b[01;34mstrawberry_shortcake\u001b[0m/\r\n",
      "\u001b[01;34mcreme_brulee\u001b[0m/  \u001b[01;34mred_velvet_cake\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls data/train_small/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1249 images belonging to 5 classes.\n",
      "Found 331 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "filepath_train = 'data/train_small/'\n",
    "filepath_val = 'data/validation_small'\n",
    "train_small = trainimggen.flow_from_directory(filepath_train, target_size=(100,100), batch_size=batch_size)\n",
    "val_small = validationimggen.flow_from_directory(filepath_val, target_size=(100,100), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compile model using your favorite optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD', loss=['categorical_crossentropy'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run your model for a few epochs using the fit_generator method. steps_per_epoch is generally equal to the number of training images / batch_size, and validation steps is number of validation images / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /usr/local/lib/python3.5/dist-packages (7.1.2)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.5/dist-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.5/dist-packages (from scipy) (1.16.2)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pillow;\n",
    "! pip install scipy;\n",
    "# If this ran something other than 'Requirement already satisfied', you will need to reset your kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 100, 100, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_small[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/0 [================================] - 4s 4s/step - loss: 1.6397 - accuracy: 0.1875\n",
      "Epoch 2/2\n",
      "1/0 [================================] - 4s 4s/step - loss: 1.6097 - accuracy: 0.2188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4290345be0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_images = 30\n",
    "steps_per_epoch = training_images / batch_size\n",
    "validation_steps = 30 / batch_size\n",
    "model.fit_generator(generator=train_small, \n",
    "                    epochs=2, \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. After you've gotten that to work, add a tensorboard callback so you can monitor training status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"transfer_learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# tensorboard = TensorBoard(log_dir=project_name, \n",
    "#                           histogram_freq=0, \n",
    "# #                           batch_size=batch_size, \n",
    "#                           write_graph=True, \n",
    "#                           embeddings_freq=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/0 [================================] - 10s 10s/step - loss: 1.6631 - accuracy: 0.1875 - val_loss: 1.7034 - val_accuracy: 0.1562\n",
      "Epoch 2/2\n",
      "1/0 [================================] - 5s 5s/step - loss: 1.6203 - accuracy: 0.2188 - val_loss: 1.7031 - val_accuracy: 0.1562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4261f6a240>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_small, \n",
    "                    validation_data=val_small,\n",
    "                    epochs=2, \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    validation_steps=validation_steps,\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f425feb5048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. The model at the end of training session is not necessarily the best model! To fix this, we will add another callback that saves our best model to disk for use later. Use keras.callbacks.ModelCheckpoint to make a callback and pass it to the fit_generator. You can use save_best_only=True to prevent saving tons of models on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘models’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/0 [================================] - 10s 10s/step - loss: 1.6420 - accuracy: 0.0938 - val_loss: 1.7040 - val_accuracy: 0.1562\n",
      "Epoch 2/2\n",
      "1/0 [================================] - 9s 9s/step - loss: 1.6500 - accuracy: 0.1875 - val_loss: 1.6995 - val_accuracy: 0.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4261f6a208>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_check = ModelCheckpoint(filepath='models/best_model.hdf5',\n",
    "                            save_best_only=True)\n",
    "model.fit_generator(generator=train_small, \n",
    "                    validation_data=val_small,\n",
    "                    epochs=2, \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    validation_steps=validation_steps,\n",
    "                    callbacks=[mdl_check, tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Finally, let's evaluate our model on the holdout set.\n",
    "First, load your best model from disk:\n",
    "```python\n",
    "from keras.models import load_model\n",
    "best_model = load_model(file_path_to_model)\n",
    "```\n",
    "You can make a holdout_generator with validation_datagen.flow_from_directory and pass it the holdout folder instead of the validation folder. Then use model.evaluate_generator(), which is very similar to fit_generator to output the holdout loss and holdout accuracy.\n",
    "\n",
    "```python\n",
    "metrics = best_model.evaluate_generator(<your code here>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model.hdf5        simple_class_test.hdf5\r\n",
      "best_trans_model.hdf5  transfer_test.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "file_path_to_model = 'models/best_model.hdf5'\n",
    "best_model = load_model(file_path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6057954593138262, 0.21450152]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = best_model.evaluate_generator(generator=val_small)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checkpoint 1: Congratulations! You just created a very practical set-up for modeling with a ConvNet, where you can read in large datasets with ease, save the best models and monitor the progress on a tensorboard!\n",
    "\n",
    "#### Step 2: Transfer Model\n",
    "\n",
    "1. Create a function that takes Xception (from keras.applications) and adds a new head for our current task onto it. Use a GlobalAveragePooling2D layer and a Dense layer with a softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 45s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_transfer_model(input_size, n_categories, weights = 'imagenet'):\n",
    "        # note that the \"top\" is not included in the weights below\n",
    "        base_model = Xception(weights=weights,\n",
    "                          include_top=False,\n",
    "                          input_shape=input_size)\n",
    "        \n",
    "        model = base_model.output\n",
    "        model = GlobalAveragePooling2D()(model)\n",
    "        predictions = Dense(n_categories, activation='softmax')(model)\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "transfer_model = create_transfer_model(input_size=(100,100,3), n_categories=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Set all of the layers except for the new head to untrainable, then compile it with you favorite optimizer. We want to warm up the head slowly, so use a lower learning rate than you normally would ~(2x to 10x smaller)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 | Name: input_1 | Trainable: True\n",
      "Layer 1 | Name: block1_conv1 | Trainable: True\n",
      "Layer 2 | Name: block1_conv1_bn | Trainable: True\n",
      "Layer 3 | Name: block1_conv1_act | Trainable: True\n",
      "Layer 4 | Name: block1_conv2 | Trainable: True\n",
      "Layer 5 | Name: block1_conv2_bn | Trainable: True\n",
      "Layer 6 | Name: block1_conv2_act | Trainable: True\n",
      "Layer 7 | Name: block2_sepconv1 | Trainable: True\n",
      "Layer 8 | Name: block2_sepconv1_bn | Trainable: True\n",
      "Layer 9 | Name: block2_sepconv2_act | Trainable: True\n",
      "Layer 10 | Name: block2_sepconv2 | Trainable: True\n",
      "Layer 11 | Name: block2_sepconv2_bn | Trainable: True\n",
      "Layer 12 | Name: conv2d_2 | Trainable: True\n",
      "Layer 13 | Name: block2_pool | Trainable: True\n",
      "Layer 14 | Name: batch_normalization_v1 | Trainable: True\n",
      "Layer 15 | Name: add | Trainable: True\n",
      "Layer 16 | Name: block3_sepconv1_act | Trainable: True\n",
      "Layer 17 | Name: block3_sepconv1 | Trainable: True\n",
      "Layer 18 | Name: block3_sepconv1_bn | Trainable: True\n",
      "Layer 19 | Name: block3_sepconv2_act | Trainable: True\n",
      "Layer 20 | Name: block3_sepconv2 | Trainable: True\n",
      "Layer 21 | Name: block3_sepconv2_bn | Trainable: True\n",
      "Layer 22 | Name: conv2d_3 | Trainable: True\n",
      "Layer 23 | Name: block3_pool | Trainable: True\n",
      "Layer 24 | Name: batch_normalization_v1_1 | Trainable: True\n",
      "Layer 25 | Name: add_1 | Trainable: True\n",
      "Layer 26 | Name: block4_sepconv1_act | Trainable: True\n",
      "Layer 27 | Name: block4_sepconv1 | Trainable: True\n",
      "Layer 28 | Name: block4_sepconv1_bn | Trainable: True\n",
      "Layer 29 | Name: block4_sepconv2_act | Trainable: True\n",
      "Layer 30 | Name: block4_sepconv2 | Trainable: True\n",
      "Layer 31 | Name: block4_sepconv2_bn | Trainable: True\n",
      "Layer 32 | Name: conv2d_4 | Trainable: True\n",
      "Layer 33 | Name: block4_pool | Trainable: True\n",
      "Layer 34 | Name: batch_normalization_v1_2 | Trainable: True\n",
      "Layer 35 | Name: add_2 | Trainable: True\n",
      "Layer 36 | Name: block5_sepconv1_act | Trainable: True\n",
      "Layer 37 | Name: block5_sepconv1 | Trainable: True\n",
      "Layer 38 | Name: block5_sepconv1_bn | Trainable: True\n",
      "Layer 39 | Name: block5_sepconv2_act | Trainable: True\n",
      "Layer 40 | Name: block5_sepconv2 | Trainable: True\n",
      "Layer 41 | Name: block5_sepconv2_bn | Trainable: True\n",
      "Layer 42 | Name: block5_sepconv3_act | Trainable: True\n",
      "Layer 43 | Name: block5_sepconv3 | Trainable: True\n",
      "Layer 44 | Name: block5_sepconv3_bn | Trainable: True\n",
      "Layer 45 | Name: add_3 | Trainable: True\n",
      "Layer 46 | Name: block6_sepconv1_act | Trainable: True\n",
      "Layer 47 | Name: block6_sepconv1 | Trainable: True\n",
      "Layer 48 | Name: block6_sepconv1_bn | Trainable: True\n",
      "Layer 49 | Name: block6_sepconv2_act | Trainable: True\n",
      "Layer 50 | Name: block6_sepconv2 | Trainable: True\n",
      "Layer 51 | Name: block6_sepconv2_bn | Trainable: True\n",
      "Layer 52 | Name: block6_sepconv3_act | Trainable: True\n",
      "Layer 53 | Name: block6_sepconv3 | Trainable: True\n",
      "Layer 54 | Name: block6_sepconv3_bn | Trainable: True\n",
      "Layer 55 | Name: add_4 | Trainable: True\n",
      "Layer 56 | Name: block7_sepconv1_act | Trainable: True\n",
      "Layer 57 | Name: block7_sepconv1 | Trainable: True\n",
      "Layer 58 | Name: block7_sepconv1_bn | Trainable: True\n",
      "Layer 59 | Name: block7_sepconv2_act | Trainable: True\n",
      "Layer 60 | Name: block7_sepconv2 | Trainable: True\n",
      "Layer 61 | Name: block7_sepconv2_bn | Trainable: True\n",
      "Layer 62 | Name: block7_sepconv3_act | Trainable: True\n",
      "Layer 63 | Name: block7_sepconv3 | Trainable: True\n",
      "Layer 64 | Name: block7_sepconv3_bn | Trainable: True\n",
      "Layer 65 | Name: add_5 | Trainable: True\n",
      "Layer 66 | Name: block8_sepconv1_act | Trainable: True\n",
      "Layer 67 | Name: block8_sepconv1 | Trainable: True\n",
      "Layer 68 | Name: block8_sepconv1_bn | Trainable: True\n",
      "Layer 69 | Name: block8_sepconv2_act | Trainable: True\n",
      "Layer 70 | Name: block8_sepconv2 | Trainable: True\n",
      "Layer 71 | Name: block8_sepconv2_bn | Trainable: True\n",
      "Layer 72 | Name: block8_sepconv3_act | Trainable: True\n",
      "Layer 73 | Name: block8_sepconv3 | Trainable: True\n",
      "Layer 74 | Name: block8_sepconv3_bn | Trainable: True\n",
      "Layer 75 | Name: add_6 | Trainable: True\n",
      "Layer 76 | Name: block9_sepconv1_act | Trainable: True\n",
      "Layer 77 | Name: block9_sepconv1 | Trainable: True\n",
      "Layer 78 | Name: block9_sepconv1_bn | Trainable: True\n",
      "Layer 79 | Name: block9_sepconv2_act | Trainable: True\n",
      "Layer 80 | Name: block9_sepconv2 | Trainable: True\n",
      "Layer 81 | Name: block9_sepconv2_bn | Trainable: True\n",
      "Layer 82 | Name: block9_sepconv3_act | Trainable: True\n",
      "Layer 83 | Name: block9_sepconv3 | Trainable: True\n",
      "Layer 84 | Name: block9_sepconv3_bn | Trainable: True\n",
      "Layer 85 | Name: add_7 | Trainable: True\n",
      "Layer 86 | Name: block10_sepconv1_act | Trainable: True\n",
      "Layer 87 | Name: block10_sepconv1 | Trainable: True\n",
      "Layer 88 | Name: block10_sepconv1_bn | Trainable: True\n",
      "Layer 89 | Name: block10_sepconv2_act | Trainable: True\n",
      "Layer 90 | Name: block10_sepconv2 | Trainable: True\n",
      "Layer 91 | Name: block10_sepconv2_bn | Trainable: True\n",
      "Layer 92 | Name: block10_sepconv3_act | Trainable: True\n",
      "Layer 93 | Name: block10_sepconv3 | Trainable: True\n",
      "Layer 94 | Name: block10_sepconv3_bn | Trainable: True\n",
      "Layer 95 | Name: add_8 | Trainable: True\n",
      "Layer 96 | Name: block11_sepconv1_act | Trainable: True\n",
      "Layer 97 | Name: block11_sepconv1 | Trainable: True\n",
      "Layer 98 | Name: block11_sepconv1_bn | Trainable: True\n",
      "Layer 99 | Name: block11_sepconv2_act | Trainable: True\n",
      "Layer 100 | Name: block11_sepconv2 | Trainable: True\n",
      "Layer 101 | Name: block11_sepconv2_bn | Trainable: True\n",
      "Layer 102 | Name: block11_sepconv3_act | Trainable: True\n",
      "Layer 103 | Name: block11_sepconv3 | Trainable: True\n",
      "Layer 104 | Name: block11_sepconv3_bn | Trainable: True\n",
      "Layer 105 | Name: add_9 | Trainable: True\n",
      "Layer 106 | Name: block12_sepconv1_act | Trainable: True\n",
      "Layer 107 | Name: block12_sepconv1 | Trainable: True\n",
      "Layer 108 | Name: block12_sepconv1_bn | Trainable: True\n",
      "Layer 109 | Name: block12_sepconv2_act | Trainable: True\n",
      "Layer 110 | Name: block12_sepconv2 | Trainable: True\n",
      "Layer 111 | Name: block12_sepconv2_bn | Trainable: True\n",
      "Layer 112 | Name: block12_sepconv3_act | Trainable: True\n",
      "Layer 113 | Name: block12_sepconv3 | Trainable: True\n",
      "Layer 114 | Name: block12_sepconv3_bn | Trainable: True\n",
      "Layer 115 | Name: add_10 | Trainable: True\n",
      "Layer 116 | Name: block13_sepconv1_act | Trainable: True\n",
      "Layer 117 | Name: block13_sepconv1 | Trainable: True\n",
      "Layer 118 | Name: block13_sepconv1_bn | Trainable: True\n",
      "Layer 119 | Name: block13_sepconv2_act | Trainable: True\n",
      "Layer 120 | Name: block13_sepconv2 | Trainable: True\n",
      "Layer 121 | Name: block13_sepconv2_bn | Trainable: True\n",
      "Layer 122 | Name: conv2d_5 | Trainable: True\n",
      "Layer 123 | Name: block13_pool | Trainable: True\n",
      "Layer 124 | Name: batch_normalization_v1_3 | Trainable: True\n",
      "Layer 125 | Name: add_11 | Trainable: True\n",
      "Layer 126 | Name: block14_sepconv1 | Trainable: True\n",
      "Layer 127 | Name: block14_sepconv1_bn | Trainable: True\n",
      "Layer 128 | Name: block14_sepconv1_act | Trainable: True\n",
      "Layer 129 | Name: block14_sepconv2 | Trainable: True\n",
      "Layer 130 | Name: block14_sepconv2_bn | Trainable: True\n",
      "Layer 131 | Name: block14_sepconv2_act | Trainable: True\n",
      "Layer 132 | Name: global_average_pooling2d | Trainable: True\n",
      "Layer 133 | Name: dense_2 | Trainable: True\n"
     ]
    }
   ],
   "source": [
    "def print_model_properties(model, indices = 0):\n",
    "     for i, layer in enumerate(model.layers[indices:]):\n",
    "        print(\"Layer {} | Name: {} | Trainable: {}\".format(i+indices, layer.name, layer.trainable))\n",
    "        \n",
    "print_model_properties(transfer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_trainable_layers(model, trainable_index):\n",
    "    for layer in model.layers[:trainable_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[trainable_index:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "change_trainable_layers(transfer_model, 132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 | Name: input_1 | Trainable: False\n",
      "Layer 1 | Name: block1_conv1 | Trainable: False\n",
      "Layer 2 | Name: block1_conv1_bn | Trainable: False\n",
      "Layer 3 | Name: block1_conv1_act | Trainable: False\n",
      "Layer 4 | Name: block1_conv2 | Trainable: False\n",
      "Layer 5 | Name: block1_conv2_bn | Trainable: False\n",
      "Layer 6 | Name: block1_conv2_act | Trainable: False\n",
      "Layer 7 | Name: block2_sepconv1 | Trainable: False\n",
      "Layer 8 | Name: block2_sepconv1_bn | Trainable: False\n",
      "Layer 9 | Name: block2_sepconv2_act | Trainable: False\n",
      "Layer 10 | Name: block2_sepconv2 | Trainable: False\n",
      "Layer 11 | Name: block2_sepconv2_bn | Trainable: False\n",
      "Layer 12 | Name: conv2d_2 | Trainable: False\n",
      "Layer 13 | Name: block2_pool | Trainable: False\n",
      "Layer 14 | Name: batch_normalization_v1 | Trainable: False\n",
      "Layer 15 | Name: add | Trainable: False\n",
      "Layer 16 | Name: block3_sepconv1_act | Trainable: False\n",
      "Layer 17 | Name: block3_sepconv1 | Trainable: False\n",
      "Layer 18 | Name: block3_sepconv1_bn | Trainable: False\n",
      "Layer 19 | Name: block3_sepconv2_act | Trainable: False\n",
      "Layer 20 | Name: block3_sepconv2 | Trainable: False\n",
      "Layer 21 | Name: block3_sepconv2_bn | Trainable: False\n",
      "Layer 22 | Name: conv2d_3 | Trainable: False\n",
      "Layer 23 | Name: block3_pool | Trainable: False\n",
      "Layer 24 | Name: batch_normalization_v1_1 | Trainable: False\n",
      "Layer 25 | Name: add_1 | Trainable: False\n",
      "Layer 26 | Name: block4_sepconv1_act | Trainable: False\n",
      "Layer 27 | Name: block4_sepconv1 | Trainable: False\n",
      "Layer 28 | Name: block4_sepconv1_bn | Trainable: False\n",
      "Layer 29 | Name: block4_sepconv2_act | Trainable: False\n",
      "Layer 30 | Name: block4_sepconv2 | Trainable: False\n",
      "Layer 31 | Name: block4_sepconv2_bn | Trainable: False\n",
      "Layer 32 | Name: conv2d_4 | Trainable: False\n",
      "Layer 33 | Name: block4_pool | Trainable: False\n",
      "Layer 34 | Name: batch_normalization_v1_2 | Trainable: False\n",
      "Layer 35 | Name: add_2 | Trainable: False\n",
      "Layer 36 | Name: block5_sepconv1_act | Trainable: False\n",
      "Layer 37 | Name: block5_sepconv1 | Trainable: False\n",
      "Layer 38 | Name: block5_sepconv1_bn | Trainable: False\n",
      "Layer 39 | Name: block5_sepconv2_act | Trainable: False\n",
      "Layer 40 | Name: block5_sepconv2 | Trainable: False\n",
      "Layer 41 | Name: block5_sepconv2_bn | Trainable: False\n",
      "Layer 42 | Name: block5_sepconv3_act | Trainable: False\n",
      "Layer 43 | Name: block5_sepconv3 | Trainable: False\n",
      "Layer 44 | Name: block5_sepconv3_bn | Trainable: False\n",
      "Layer 45 | Name: add_3 | Trainable: False\n",
      "Layer 46 | Name: block6_sepconv1_act | Trainable: False\n",
      "Layer 47 | Name: block6_sepconv1 | Trainable: False\n",
      "Layer 48 | Name: block6_sepconv1_bn | Trainable: False\n",
      "Layer 49 | Name: block6_sepconv2_act | Trainable: False\n",
      "Layer 50 | Name: block6_sepconv2 | Trainable: False\n",
      "Layer 51 | Name: block6_sepconv2_bn | Trainable: False\n",
      "Layer 52 | Name: block6_sepconv3_act | Trainable: False\n",
      "Layer 53 | Name: block6_sepconv3 | Trainable: False\n",
      "Layer 54 | Name: block6_sepconv3_bn | Trainable: False\n",
      "Layer 55 | Name: add_4 | Trainable: False\n",
      "Layer 56 | Name: block7_sepconv1_act | Trainable: False\n",
      "Layer 57 | Name: block7_sepconv1 | Trainable: False\n",
      "Layer 58 | Name: block7_sepconv1_bn | Trainable: False\n",
      "Layer 59 | Name: block7_sepconv2_act | Trainable: False\n",
      "Layer 60 | Name: block7_sepconv2 | Trainable: False\n",
      "Layer 61 | Name: block7_sepconv2_bn | Trainable: False\n",
      "Layer 62 | Name: block7_sepconv3_act | Trainable: False\n",
      "Layer 63 | Name: block7_sepconv3 | Trainable: False\n",
      "Layer 64 | Name: block7_sepconv3_bn | Trainable: False\n",
      "Layer 65 | Name: add_5 | Trainable: False\n",
      "Layer 66 | Name: block8_sepconv1_act | Trainable: False\n",
      "Layer 67 | Name: block8_sepconv1 | Trainable: False\n",
      "Layer 68 | Name: block8_sepconv1_bn | Trainable: False\n",
      "Layer 69 | Name: block8_sepconv2_act | Trainable: False\n",
      "Layer 70 | Name: block8_sepconv2 | Trainable: False\n",
      "Layer 71 | Name: block8_sepconv2_bn | Trainable: False\n",
      "Layer 72 | Name: block8_sepconv3_act | Trainable: False\n",
      "Layer 73 | Name: block8_sepconv3 | Trainable: False\n",
      "Layer 74 | Name: block8_sepconv3_bn | Trainable: False\n",
      "Layer 75 | Name: add_6 | Trainable: False\n",
      "Layer 76 | Name: block9_sepconv1_act | Trainable: False\n",
      "Layer 77 | Name: block9_sepconv1 | Trainable: False\n",
      "Layer 78 | Name: block9_sepconv1_bn | Trainable: False\n",
      "Layer 79 | Name: block9_sepconv2_act | Trainable: False\n",
      "Layer 80 | Name: block9_sepconv2 | Trainable: False\n",
      "Layer 81 | Name: block9_sepconv2_bn | Trainable: False\n",
      "Layer 82 | Name: block9_sepconv3_act | Trainable: False\n",
      "Layer 83 | Name: block9_sepconv3 | Trainable: False\n",
      "Layer 84 | Name: block9_sepconv3_bn | Trainable: False\n",
      "Layer 85 | Name: add_7 | Trainable: False\n",
      "Layer 86 | Name: block10_sepconv1_act | Trainable: False\n",
      "Layer 87 | Name: block10_sepconv1 | Trainable: False\n",
      "Layer 88 | Name: block10_sepconv1_bn | Trainable: False\n",
      "Layer 89 | Name: block10_sepconv2_act | Trainable: False\n",
      "Layer 90 | Name: block10_sepconv2 | Trainable: False\n",
      "Layer 91 | Name: block10_sepconv2_bn | Trainable: False\n",
      "Layer 92 | Name: block10_sepconv3_act | Trainable: False\n",
      "Layer 93 | Name: block10_sepconv3 | Trainable: False\n",
      "Layer 94 | Name: block10_sepconv3_bn | Trainable: False\n",
      "Layer 95 | Name: add_8 | Trainable: False\n",
      "Layer 96 | Name: block11_sepconv1_act | Trainable: False\n",
      "Layer 97 | Name: block11_sepconv1 | Trainable: False\n",
      "Layer 98 | Name: block11_sepconv1_bn | Trainable: False\n",
      "Layer 99 | Name: block11_sepconv2_act | Trainable: False\n",
      "Layer 100 | Name: block11_sepconv2 | Trainable: False\n",
      "Layer 101 | Name: block11_sepconv2_bn | Trainable: False\n",
      "Layer 102 | Name: block11_sepconv3_act | Trainable: False\n",
      "Layer 103 | Name: block11_sepconv3 | Trainable: False\n",
      "Layer 104 | Name: block11_sepconv3_bn | Trainable: False\n",
      "Layer 105 | Name: add_9 | Trainable: False\n",
      "Layer 106 | Name: block12_sepconv1_act | Trainable: False\n",
      "Layer 107 | Name: block12_sepconv1 | Trainable: False\n",
      "Layer 108 | Name: block12_sepconv1_bn | Trainable: False\n",
      "Layer 109 | Name: block12_sepconv2_act | Trainable: False\n",
      "Layer 110 | Name: block12_sepconv2 | Trainable: False\n",
      "Layer 111 | Name: block12_sepconv2_bn | Trainable: False\n",
      "Layer 112 | Name: block12_sepconv3_act | Trainable: False\n",
      "Layer 113 | Name: block12_sepconv3 | Trainable: False\n",
      "Layer 114 | Name: block12_sepconv3_bn | Trainable: False\n",
      "Layer 115 | Name: add_10 | Trainable: False\n",
      "Layer 116 | Name: block13_sepconv1_act | Trainable: False\n",
      "Layer 117 | Name: block13_sepconv1 | Trainable: False\n",
      "Layer 118 | Name: block13_sepconv1_bn | Trainable: False\n",
      "Layer 119 | Name: block13_sepconv2_act | Trainable: False\n",
      "Layer 120 | Name: block13_sepconv2 | Trainable: False\n",
      "Layer 121 | Name: block13_sepconv2_bn | Trainable: False\n",
      "Layer 122 | Name: conv2d_5 | Trainable: False\n",
      "Layer 123 | Name: block13_pool | Trainable: False\n",
      "Layer 124 | Name: batch_normalization_v1_3 | Trainable: False\n",
      "Layer 125 | Name: add_11 | Trainable: False\n",
      "Layer 126 | Name: block14_sepconv1 | Trainable: False\n",
      "Layer 127 | Name: block14_sepconv1_bn | Trainable: False\n",
      "Layer 128 | Name: block14_sepconv1_act | Trainable: False\n",
      "Layer 129 | Name: block14_sepconv2 | Trainable: False\n",
      "Layer 130 | Name: block14_sepconv2_bn | Trainable: False\n",
      "Layer 131 | Name: block14_sepconv2_act | Trainable: False\n",
      "Layer 132 | Name: global_average_pooling2d | Trainable: True\n",
      "Layer 133 | Name: dense_2 | Trainable: True\n"
     ]
    }
   ],
   "source": [
    "print_model_properties(transfer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. From here, you can run the warmup phase the same way that you ran the simple model with the generators and the fit_generator method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/0 [================================] - 33s 33s/step - loss: 1.5019 - accuracy: 0.3750 - val_loss: 2.2265 - val_accuracy: 0.1250\n",
      "Epoch 2/2\n",
      "1/0 [================================] - 12s 12s/step - loss: 1.6268 - accuracy: 0.1250 - val_loss: 2.2263 - val_accuracy: 0.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f41f80d4f60>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_model.compile(optimizer='SGD', loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "mdl_check_trans = ModelCheckpoint(filepath='models/best_trans_model.hdf5',\n",
    "                            save_best_only=True)\n",
    "transfer_model.fit_generator(generator=train_small, \n",
    "                    validation_data=val_small,\n",
    "                    epochs=2, \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    validation_steps=validation_steps,\n",
    "                    callbacks=[mdl_check_trans, tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. After a few warmup epochs, unfreeze the 14th convolutional block onward, recompile and continue training, again with a low learning rate or an adaptive optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/0 [================================] - 30s 30s/step - loss: 1.6553 - accuracy: 0.3438 - val_loss: 2.2215 - val_accuracy: 0.1250\n",
      "Epoch 2/2\n",
      "1/0 [================================] - 8s 8s/step - loss: 1.6043 - accuracy: 0.1875 - val_loss: 2.2218 - val_accuracy: 0.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f41f0d04898>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_trainable_layers(transfer_model, 126)\n",
    "transfer_model.compile(optimizer='SGD', loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "\n",
    "transfer_model.fit_generator(generator=train_small, \n",
    "                    validation_data=val_small,\n",
    "                    epochs=2, \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    validation_steps=validation_steps,\n",
    "                    callbacks=[mdl_check_trans])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Evaluate your performance on with the transfer model. Is it better than the simple ConvNet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6074773506684736, 0.21450152]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "file_path_to_trans_model = 'models/best_trans_model.hdf5'\n",
    "best_trans_model = load_model(file_path_to_trans_model)\n",
    "\n",
    "metrics = best_model.evaluate_generator(generator=val_small)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Play around with different hyperparameters, optimizers and even base models (try mobilenet, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I would change the optimizer next. Then perhaps another base model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint 2: Nice work! You just performed surgery on a neural network and retrained it to your particular task! This is a really powerful method for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
